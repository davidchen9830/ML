{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((len(X_train), -1))\n",
    "X_test = X_test.reshape((len(X_test), -1))\n",
    "\n",
    "X_train = np.asarray(X_train, dtype=np.float32)\n",
    "X_test = np.asarray(X_test, dtype=np.float32)\n",
    "\n",
    "y_train = np.asarray(y_train, dtype=np.int32)\n",
    "y_test = np.asarray(y_test, dtype=np.int32)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test) # Center and Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(num_classes, y):\n",
    "    return np.eye(num_classes)[y]\n",
    "\n",
    "# Acurracy\n",
    "def accuracy(y_pred, y_true):\n",
    "    return np.mean(y_pred == y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    def __init__(self, input_shape):\n",
    "        initializer = tf.keras.initializers.GlorotUniform()\n",
    "        \n",
    "        self.w1 = tf.Variable(initializer(shape=(input_shape, 50)))\n",
    "        self.b1 = tf.Variable(tf.zeros([50]))\n",
    "        \n",
    "        self.w2 = tf.Variable(initializer(shape=(50, 10)))\n",
    "        self.b2 = tf.Variable(tf.zeros([10]))\n",
    "        \n",
    "    def __call__(self, inputs):\n",
    "        return self.forward(inputs)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        z1 = tf.matmul(inputs, self.w1) + self.b1\n",
    "        a1 = tf.keras.activations.relu(z1)\n",
    "        \n",
    "        z2 = tf.matmul(z1, self.w2) + self.b2\n",
    "        a2 = tf.keras.activations.softmax(z2)\n",
    "        \n",
    "        return a2\n",
    "    \n",
    "    def train(self, X_train, y_train,\n",
    "             epochs=10,\n",
    "             batch_size = 32):\n",
    "        # Batch dataset\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "        dataset = dataset.shuffle(buffer_size=10000, seed=42)\n",
    "        dataset = dataset.batch(batch_size=batch_size)\n",
    "        # Loss Function\n",
    "        loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        # Optimizer\n",
    "        optimizer = tf.keras.optimizers.Adam()\n",
    "        \n",
    "        losses = []\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            for (inputs, targets) in dataset:\n",
    "                targets = one_hot(10, targets)\n",
    "                with tf.GradientTape() as tape:\n",
    "                    output = self.forward(inputs)\n",
    "                    loss = loss_fn(output, targets)\n",
    "                    losses.append(loss)\n",
    "                variables = [self.w1, self.b1, self.w2, self.b2]\n",
    "                grads = tape.gradient(loss, variables)\n",
    "                optimizer.apply_gradients(zip(grads, variables))\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8436\n",
      "CPU times: user 19min 35s, sys: 44.1 s, total: 20min 19s\n",
      "Wall time: 16min 43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f999822dba8>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = NeuralNet(X_train.shape[1])\n",
    "losses = model.train(X_train, y_train, epochs)\n",
    "\n",
    "pred_y = model.forward(X_test)\n",
    "pred_y = np.argmax(pred_y, axis=1)\n",
    "print(accuracy(pred_y, y_test))\n",
    "\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8678\n",
      "CPU times: user 4min 43s, sys: 36.8 s, total: 5min 20s\n",
      "Wall time: 2min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(50, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=epochs, verbose=False)\n",
    "pred_y = model.predict(X_test)\n",
    "pred_y = np.argmax(pred_y, axis=1)\n",
    "cluster data into k clusters\n",
    "print(accuracy(pred_y, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8678\n"
     ]
    }
   ],
   "source": [
    "pred_y = model.predict(X_test)\n",
    "pred_y = np.argmax(pred_y, axis=1)\n",
    "\n",
    "print(accuracy(pred_y, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(x, y, batch_size=32):\n",
    "    train_data = []\n",
    "    for i in range(len(x)):\n",
    "        train_data.append([x[i], y[i]])\n",
    "    return DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 12s, sys: 0 ns, total: 12min 12s\n",
      "Wall time: 3min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(X_train.shape[1], 50),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(50, 10)\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001) # Keras lr\n",
    "train_dl = gen_dataset(X_train, y_train)\n",
    "\n",
    "for e in range(epochs):\n",
    "    for (inputs, targets) in train_dl:\n",
    "        y_pred = model(inputs)\n",
    "        \n",
    "        loss = loss_fn(y_pred, targets.type(torch.long))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8627\n"
     ]
    }
   ],
   "source": [
    "pred_y = torch.nn.Softmax(dim=1)(model(torch.tensor(X_test))).detach().numpy()\n",
    "pred_y = np.argmax(pred_y, axis=1)\n",
    "\n",
    "print(accuracy(pred_y, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classic classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8766\n",
      "CPU times: user 1min 23s, sys: 0 ns, total: 1min 23s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfm = RandomForestClassifier() # We don't tweak any values\n",
    "rfm.fit(X_train, y_train)\n",
    "\n",
    "pred_y = rfm.predict(X_test)\n",
    "print(accuracy(pred_y, y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1754\n",
      "CPU times: user 4min 12s, sys: 1min 42s, total: 5min 54s\n",
      "Wall time: 47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(X_train)\n",
    "\n",
    "pred_y = kmeans.predict(X_test)\n",
    "print(accuracy(pred_y, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
